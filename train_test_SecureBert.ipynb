{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the best F1-score on the first 50 epochs and extract the best model\n",
    "\n",
    "Embedded: CVE description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "   5/2516 [..............................] - ETA: 33s - loss: 4.1556 - accuracy: 0.0375    WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_train_batch_end` time: 0.0048s). Check your callbacks.\n",
      "280/280 [==============================] - 1s 2ms/step loss: 2.4979\n",
      "Epoch 1 - F1 Score: 0.3914\n",
      "Saved best model\n",
      "[0.3914425229897259]\n",
      "2516/2516 [==============================] - 13s 4ms/step - loss: 2.4949 - accuracy: 0.3262 - val_loss: 1.9864 - val_accuracy: 0.4349\n",
      "Epoch 2/60\n",
      "280/280 [==============================] - 1s 2ms/step loss: 1.\n",
      "Epoch 2 - F1 Score: 0.4691\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765]\n",
      "2516/2516 [==============================] - 10s 4ms/step - loss: 1.8523 - accuracy: 0.4742 - val_loss: 1.7586 - val_accuracy: 0.5052\n",
      "Epoch 3/60\n",
      "280/280 [==============================] - 1s 3ms/step loss\n",
      "Epoch 3 - F1 Score: 0.4919\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007]\n",
      "2516/2516 [==============================] - 16s 6ms/step - loss: 1.6850 - accuracy: 0.5154 - val_loss: 1.6592 - val_accuracy: 0.5239\n",
      "Epoch 4/60\n",
      "280/280 [==============================] - 1s 2ms/step loss: 1.5\n",
      "Epoch 4 - F1 Score: 0.5060\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363]\n",
      "2516/2516 [==============================] - 11s 4ms/step - loss: 1.5767 - accuracy: 0.5444 - val_loss: 1.5763 - val_accuracy: 0.5444\n",
      "Epoch 5/60\n",
      "280/280 [==============================] - 1s 2ms/step loss: \n",
      "Epoch 5 - F1 Score: 0.5434\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106]\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 1.4972 - accuracy: 0.5655 - val_loss: 1.4915 - val_accuracy: 0.5685\n",
      "Epoch 6/60\n",
      "280/280 [==============================] - 1s 3ms/step lo\n",
      "Epoch 6 - F1 Score: 0.5586\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521]\n",
      "2516/2516 [==============================] - 14s 6ms/step - loss: 1.4404 - accuracy: 0.5809 - val_loss: 1.4424 - val_accuracy: 0.5846\n",
      "Epoch 7/60\n",
      "280/280 [==============================] - 1s 2ms/step loss: \n",
      "Epoch 7 - F1 Score: 0.5661\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554]\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 1.3954 - accuracy: 0.5946 - val_loss: 1.4260 - val_accuracy: 0.5850\n",
      "Epoch 8/60\n",
      "280/280 [==============================] - 0s 2ms/step loss: 1.3615 -\n",
      "Epoch 8 - F1 Score: 0.5767\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409]\n",
      "2516/2516 [==============================] - 11s 4ms/step - loss: 1.3614 - accuracy: 0.6023 - val_loss: 1.3889 - val_accuracy: 0.5982\n",
      "Epoch 9/60\n",
      "280/280 [==============================] - 1s 5ms/step\n",
      "Epoch 9 - F1 Score: 0.5855\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108]\n",
      "2516/2516 [==============================] - 28s 11ms/step - loss: 1.3306 - accuracy: 0.6116 - val_loss: 1.3881 - val_accuracy: 0.6027\n",
      "Epoch 10/60\n",
      "280/280 [==============================] - 2s 5ms/step\n",
      "Epoch 10 - F1 Score: 0.5918\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499]\n",
      "2516/2516 [==============================] - 26s 10ms/step - loss: 1.3061 - accuracy: 0.6188 - val_loss: 1.3499 - val_accuracy: 0.6074\n",
      "Epoch 11/60\n",
      "280/280 [==============================] - 1s 5ms/step\n",
      "Epoch 11 - F1 Score: 0.5943\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292]\n",
      "2516/2516 [==============================] - 30s 12ms/step - loss: 1.2824 - accuracy: 0.6232 - val_loss: 1.3448 - val_accuracy: 0.6062\n",
      "Epoch 12/60\n",
      "280/280 [==============================] - 2s 6ms/step\n",
      "Epoch 12 - F1 Score: 0.5944\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953]\n",
      "2516/2516 [==============================] - 27s 11ms/step - loss: 1.2609 - accuracy: 0.6309 - val_loss: 1.3577 - val_accuracy: 0.6070\n",
      "Epoch 13/60\n",
      "280/280 [==============================] - 1s 4ms/step\n",
      "Epoch 13 - F1 Score: 0.6065\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059]\n",
      "2516/2516 [==============================] - 29s 12ms/step - loss: 1.2437 - accuracy: 0.6341 - val_loss: 1.3141 - val_accuracy: 0.6193\n",
      "Epoch 14/60\n",
      "280/280 [==============================] - 1s 3ms/step\n",
      "2516/2516 [==============================] - 22s 9ms/step - loss: 1.2252 - accuracy: 0.6410 - val_loss: 1.3011 - val_accuracy: 0.6187\n",
      "Epoch 15/60\n",
      "280/280 [==============================] - 1s 3ms/step \n",
      "2516/2516 [==============================] - 25s 10ms/step - loss: 1.2126 - accuracy: 0.6433 - val_loss: 1.3005 - val_accuracy: 0.6221\n",
      "Epoch 16/60\n",
      "280/280 [==============================] - 1s 3ms/step lo\n",
      "Epoch 16 - F1 Score: 0.6119\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924]\n",
      "2516/2516 [==============================] - 18s 7ms/step - loss: 1.1978 - accuracy: 0.6470 - val_loss: 1.2745 - val_accuracy: 0.6276\n",
      "Epoch 17/60\n",
      "280/280 [==============================] - 2s 8ms/step\n",
      "Epoch 17 - F1 Score: 0.6190\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511]\n",
      "2516/2516 [==============================] - 25s 10ms/step - loss: 1.1834 - accuracy: 0.6506 - val_loss: 1.2643 - val_accuracy: 0.6309\n",
      "Epoch 18/60\n",
      "280/280 [==============================] - 2s 7ms/step\n",
      "2516/2516 [==============================] - 42s 17ms/step - loss: 1.1721 - accuracy: 0.6547 - val_loss: 1.2634 - val_accuracy: 0.6365\n",
      "Epoch 19/60\n",
      "280/280 [==============================] - 1s 5ms/step\n",
      "2516/2516 [==============================] - 36s 14ms/step - loss: 1.1594 - accuracy: 0.6574 - val_loss: 1.2686 - val_accuracy: 0.6300\n",
      "Epoch 20/60\n",
      "280/280 [==============================] - 1s 4ms/step\n",
      "Epoch 20 - F1 Score: 0.6203\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441]\n",
      "2516/2516 [==============================] - 25s 10ms/step - loss: 1.1505 - accuracy: 0.6598 - val_loss: 1.2536 - val_accuracy: 0.6346\n",
      "Epoch 21/60\n",
      "280/280 [==============================] - 2s 6ms/step\n",
      "Epoch 21 - F1 Score: 0.6243\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929]\n",
      "2516/2516 [==============================] - 42s 17ms/step - loss: 1.1388 - accuracy: 0.6630 - val_loss: 1.2392 - val_accuracy: 0.6405\n",
      "Epoch 22/60\n",
      "280/280 [==============================] - 2s 8ms/step\n",
      "2516/2516 [==============================] - 55s 22ms/step - loss: 1.1304 - accuracy: 0.6661 - val_loss: 1.2613 - val_accuracy: 0.6326\n",
      "Epoch 23/60\n",
      "280/280 [==============================] - 3s 9ms/step\n",
      "Epoch 23 - F1 Score: 0.6248\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861]\n",
      "2516/2516 [==============================] - 50s 20ms/step - loss: 1.1201 - accuracy: 0.6680 - val_loss: 1.2486 - val_accuracy: 0.6369\n",
      "Epoch 24/60\n",
      "280/280 [==============================] - 3s 9ms/step\n",
      "2516/2516 [==============================] - 51s 20ms/step - loss: 1.1119 - accuracy: 0.6689 - val_loss: 1.2555 - val_accuracy: 0.6382\n",
      "Epoch 25/60\n",
      "280/280 [==============================] - 3s 9ms/step\n",
      "Epoch 25 - F1 Score: 0.6276\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861, 0.6218415039980172, 0.6276300822148972]\n",
      "2516/2516 [==============================] - 50s 20ms/step - loss: 1.1035 - accuracy: 0.6735 - val_loss: 1.2444 - val_accuracy: 0.6412\n",
      "Epoch 26/60\n",
      "280/280 [==============================] - 2s 6ms/step\n",
      "2516/2516 [==============================] - 53s 21ms/step - loss: 1.0964 - accuracy: 0.6769 - val_loss: 1.2731 - val_accuracy: 0.6377\n",
      "Epoch 27/60\n",
      "280/280 [==============================] - 2s 7ms/step\n",
      "Epoch 27 - F1 Score: 0.6321\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861, 0.6218415039980172, 0.6276300822148972, 0.6194488341534861, 0.6321429088235874]\n",
      "2516/2516 [==============================] - 51s 20ms/step - loss: 1.0879 - accuracy: 0.6763 - val_loss: 1.2338 - val_accuracy: 0.6444\n",
      "Epoch 28/60\n",
      "280/280 [==============================] - 3s 9ms/step\n",
      "2516/2516 [==============================] - 47s 19ms/step - loss: 1.0809 - accuracy: 0.6800 - val_loss: 1.2349 - val_accuracy: 0.6392\n",
      "Epoch 29/60\n",
      "280/280 [==============================] - 3s 8ms/step\n",
      "Epoch 29 - F1 Score: 0.6383\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861, 0.6218415039980172, 0.6276300822148972, 0.6194488341534861, 0.6321429088235874, 0.6278090128871654, 0.6383277289708013]\n",
      "2516/2516 [==============================] - 47s 19ms/step - loss: 1.0733 - accuracy: 0.6811 - val_loss: 1.2338 - val_accuracy: 0.6464\n",
      "Epoch 30/60\n",
      "280/280 [==============================] - 3s 9ms/step\n",
      "2516/2516 [==============================] - 53s 21ms/step - loss: 1.0659 - accuracy: 0.6831 - val_loss: 1.2471 - val_accuracy: 0.6444\n",
      "Epoch 31/60\n",
      "280/280 [==============================] - 3s 8ms/step\n",
      "Epoch 31 - F1 Score: 0.6426\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861, 0.6218415039980172, 0.6276300822148972, 0.6194488341534861, 0.6321429088235874, 0.6278090128871654, 0.6383277289708013, 0.63268946082887, 0.6425724430075943]\n",
      "2516/2516 [==============================] - 52s 21ms/step - loss: 1.0596 - accuracy: 0.6845 - val_loss: 1.2139 - val_accuracy: 0.6541\n",
      "Epoch 32/60\n",
      "280/280 [==============================] - 3s 10ms/step\n",
      "2516/2516 [==============================] - 51s 20ms/step - loss: 1.0533 - accuracy: 0.6847 - val_loss: 1.2250 - val_accuracy: 0.6507\n",
      "Epoch 33/60\n",
      "280/280 [==============================] - 3s 9ms/step\n",
      "2516/2516 [==============================] - 50s 20ms/step - loss: 1.0470 - accuracy: 0.6867 - val_loss: 1.2459 - val_accuracy: 0.6423\n",
      "Epoch 34/60\n",
      "280/280 [==============================] - 2s 7ms/step\n",
      "2516/2516 [==============================] - 51s 20ms/step - loss: 1.0403 - accuracy: 0.6891 - val_loss: 1.2297 - val_accuracy: 0.6510\n",
      "Epoch 35/60\n",
      "280/280 [==============================] - 2s 7ms/step\n",
      "2516/2516 [==============================] - 53s 21ms/step - loss: 1.0352 - accuracy: 0.6902 - val_loss: 1.2415 - val_accuracy: 0.6453\n",
      "Epoch 36/60\n",
      "280/280 [==============================] - 3s 8ms/step\n",
      "2516/2516 [==============================] - 54s 22ms/step - loss: 1.0288 - accuracy: 0.6926 - val_loss: 1.2237 - val_accuracy: 0.6451\n",
      "Epoch 37/60\n",
      "280/280 [==============================] - 3s 9ms/step\n",
      "2516/2516 [==============================] - 48s 19ms/step - loss: 1.0234 - accuracy: 0.6936 - val_loss: 1.2148 - val_accuracy: 0.6513\n",
      "Epoch 38/60\n",
      "280/280 [==============================] - 3s 9ms/step\n",
      "2516/2516 [==============================] - 51s 20ms/step - loss: 1.0183 - accuracy: 0.6957 - val_loss: 1.2402 - val_accuracy: 0.6471\n",
      "Epoch 39/60\n",
      "280/280 [==============================] - 2s 6ms/step\n",
      "2516/2516 [==============================] - 50s 20ms/step - loss: 1.0139 - accuracy: 0.6960 - val_loss: 1.2425 - val_accuracy: 0.6465\n",
      "Epoch 40/60\n",
      "280/280 [==============================] - 3s 8ms/step\n",
      "2516/2516 [==============================] - 55s 22ms/step - loss: 1.0099 - accuracy: 0.6974 - val_loss: 1.2183 - val_accuracy: 0.6512\n",
      "Epoch 41/60\n",
      "280/280 [==============================] - 1s 3ms/step\n",
      "2516/2516 [==============================] - 14s 6ms/step - loss: 1.0043 - accuracy: 0.7001 - val_loss: 1.2178 - val_accuracy: 0.6524\n",
      "Epoch 42/60\n",
      "280/280 [==============================] - 1s 3ms/step \n",
      "Epoch 42 - F1 Score: 0.6435\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861, 0.6218415039980172, 0.6276300822148972, 0.6194488341534861, 0.6321429088235874, 0.6278090128871654, 0.6383277289708013, 0.63268946082887, 0.6425724430075943, 0.6378930298491435, 0.6351180327799265, 0.6408659866023415, 0.6377002371562281, 0.636374975447342, 0.6408474137073908, 0.6354094203871226, 0.6386355410067799, 0.638221842133951, 0.6410066416894051, 0.6434562148547458]\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9988 - accuracy: 0.7008 - val_loss: 1.2174 - val_accuracy: 0.6537\n",
      "Epoch 43/60\n",
      "280/280 [==============================] - 1s 3ms/step\n",
      "Epoch 43 - F1 Score: 0.6442\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861, 0.6218415039980172, 0.6276300822148972, 0.6194488341534861, 0.6321429088235874, 0.6278090128871654, 0.6383277289708013, 0.63268946082887, 0.6425724430075943, 0.6378930298491435, 0.6351180327799265, 0.6408659866023415, 0.6377002371562281, 0.636374975447342, 0.6408474137073908, 0.6354094203871226, 0.6386355410067799, 0.638221842133951, 0.6410066416894051, 0.6434562148547458, 0.6442366533677021]\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9922 - accuracy: 0.7024 - val_loss: 1.2292 - val_accuracy: 0.6534\n",
      "Epoch 44/60\n",
      "280/280 [==============================] - 1s 2ms/step loss\n",
      "Epoch 44 - F1 Score: 0.6459\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861, 0.6218415039980172, 0.6276300822148972, 0.6194488341534861, 0.6321429088235874, 0.6278090128871654, 0.6383277289708013, 0.63268946082887, 0.6425724430075943, 0.6378930298491435, 0.6351180327799265, 0.6408659866023415, 0.6377002371562281, 0.636374975447342, 0.6408474137073908, 0.6354094203871226, 0.6386355410067799, 0.638221842133951, 0.6410066416894051, 0.6434562148547458, 0.6442366533677021, 0.6459396602472876]\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9897 - accuracy: 0.7039 - val_loss: 1.2234 - val_accuracy: 0.6536\n",
      "Epoch 45/60\n",
      "280/280 [==============================] - 1s 2ms/step loss\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9839 - accuracy: 0.7044 - val_loss: 1.2199 - val_accuracy: 0.6479\n",
      "Epoch 46/60\n",
      "280/280 [==============================] - 1s 3ms/step \n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9813 - accuracy: 0.7065 - val_loss: 1.2281 - val_accuracy: 0.6510\n",
      "Epoch 47/60\n",
      "280/280 [==============================] - 1s 3ms/step \n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9772 - accuracy: 0.7053 - val_loss: 1.2279 - val_accuracy: 0.6492\n",
      "Epoch 48/60\n",
      "280/280 [==============================] - 1s 3ms/step lo\n",
      "2516/2516 [==============================] - 16s 6ms/step - loss: 0.9726 - accuracy: 0.7073 - val_loss: 1.2444 - val_accuracy: 0.6462\n",
      "Epoch 49/60\n",
      "280/280 [==============================] - 1s 3ms/step \n",
      "2516/2516 [==============================] - 14s 6ms/step - loss: 0.9699 - accuracy: 0.7090 - val_loss: 1.2293 - val_accuracy: 0.6522\n",
      "Epoch 50/60\n",
      "280/280 [==============================] - 1s 2ms/step loss: \n",
      "Epoch 50 - F1 Score: 0.6483\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861, 0.6218415039980172, 0.6276300822148972, 0.6194488341534861, 0.6321429088235874, 0.6278090128871654, 0.6383277289708013, 0.63268946082887, 0.6425724430075943, 0.6378930298491435, 0.6351180327799265, 0.6408659866023415, 0.6377002371562281, 0.636374975447342, 0.6408474137073908, 0.6354094203871226, 0.6386355410067799, 0.638221842133951, 0.6410066416894051, 0.6434562148547458, 0.6442366533677021, 0.6459396602472876, 0.6379833310492877, 0.643350156880396, 0.6395356890252283, 0.6340751300233045, 0.6446183558530617, 0.648310749653537]\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9653 - accuracy: 0.7096 - val_loss: 1.2279 - val_accuracy: 0.6566\n",
      "Epoch 51/60\n",
      "280/280 [==============================] - 1s 3ms/step lo\n",
      "Epoch 51 - F1 Score: 0.6500\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861, 0.6218415039980172, 0.6276300822148972, 0.6194488341534861, 0.6321429088235874, 0.6278090128871654, 0.6383277289708013, 0.63268946082887, 0.6425724430075943, 0.6378930298491435, 0.6351180327799265, 0.6408659866023415, 0.6377002371562281, 0.636374975447342, 0.6408474137073908, 0.6354094203871226, 0.6386355410067799, 0.638221842133951, 0.6410066416894051, 0.6434562148547458, 0.6442366533677021, 0.6459396602472876, 0.6379833310492877, 0.643350156880396, 0.6395356890252283, 0.6340751300233045, 0.6446183558530617, 0.648310749653537, 0.6500108171297543]\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9593 - accuracy: 0.7122 - val_loss: 1.2148 - val_accuracy: 0.6586\n",
      "Epoch 52/60\n",
      "280/280 [==============================] - 1s 2ms/step loss: \n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9575 - accuracy: 0.7131 - val_loss: 1.2388 - val_accuracy: 0.6501\n",
      "Epoch 53/60\n",
      "280/280 [==============================] - 1s 3ms/step lo\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9529 - accuracy: 0.7126 - val_loss: 1.2638 - val_accuracy: 0.6454\n",
      "Epoch 54/60\n",
      "280/280 [==============================] - 1s 3ms/step loss\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9506 - accuracy: 0.7131 - val_loss: 1.2426 - val_accuracy: 0.6527\n",
      "Epoch 55/60\n",
      "280/280 [==============================] - 1s 3ms/step lo\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9450 - accuracy: 0.7162 - val_loss: 1.2386 - val_accuracy: 0.6502\n",
      "Epoch 56/60\n",
      "280/280 [==============================] - 1s 3ms/step l\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9434 - accuracy: 0.7162 - val_loss: 1.2195 - val_accuracy: 0.6556\n",
      "Epoch 57/60\n",
      "280/280 [==============================] - 1s 2ms/step loss: \n",
      "2516/2516 [==============================] - 14s 6ms/step - loss: 0.9394 - accuracy: 0.7168 - val_loss: 1.2410 - val_accuracy: 0.6491\n",
      "Epoch 58/60\n",
      "280/280 [==============================] - 1s 3ms/step lo\n",
      "Epoch 58 - F1 Score: 0.6511\n",
      "Saved best model\n",
      "[0.3914425229897259, 0.4691207418073765, 0.49190911561652007, 0.5059778753117363, 0.5434348014930106, 0.5586295597628521, 0.566089205297554, 0.5767084292505409, 0.5854982796825108, 0.5917973105568499, 0.5943279281002292, 0.5944445244661953, 0.6065311173263059, 0.6048415694115298, 0.6055384427277316, 0.6118844023705924, 0.6189933194350511, 0.6181898520200345, 0.6124889668219183, 0.6202508711580441, 0.6243315387112929, 0.621456507083272, 0.6247633526403861, 0.6218415039980172, 0.6276300822148972, 0.6194488341534861, 0.6321429088235874, 0.6278090128871654, 0.6383277289708013, 0.63268946082887, 0.6425724430075943, 0.6378930298491435, 0.6351180327799265, 0.6408659866023415, 0.6377002371562281, 0.636374975447342, 0.6408474137073908, 0.6354094203871226, 0.6386355410067799, 0.638221842133951, 0.6410066416894051, 0.6434562148547458, 0.6442366533677021, 0.6459396602472876, 0.6379833310492877, 0.643350156880396, 0.6395356890252283, 0.6340751300233045, 0.6446183558530617, 0.648310749653537, 0.6500108171297543, 0.6446184476125765, 0.6433013979627223, 0.6432835599904763, 0.6420197643526419, 0.646445404053149, 0.6445444916187537, 0.6510930272419433]\n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9343 - accuracy: 0.7193 - val_loss: 1.2148 - val_accuracy: 0.6588\n",
      "Epoch 59/60\n",
      "280/280 [==============================] - 1s 3ms/step \n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9317 - accuracy: 0.7170 - val_loss: 1.2392 - val_accuracy: 0.6480\n",
      "Epoch 60/60\n",
      "280/280 [==============================] - 1s 3ms/step \n",
      "2516/2516 [==============================] - 15s 6ms/step - loss: 0.9284 - accuracy: 0.7196 - val_loss: 1.2184 - val_accuracy: 0.6566\n",
      "485/485 [==============================] - 2s 3ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8761    0.4157    0.5638      1174\n",
      "         120     0.2766    0.8325    0.4152       203\n",
      "         125     0.7542    0.7780    0.7659       572\n",
      "         134     0.3696    0.8947    0.5231        19\n",
      "         189     0.4725    0.8655    0.6113       119\n",
      "         190     0.5184    0.8086    0.6318       209\n",
      "          20     0.4728    0.1897    0.2707       870\n",
      "         200     0.7646    0.4668    0.5797       647\n",
      "         203     0.6744    0.8056    0.7342        36\n",
      "          22     0.8696    0.8681    0.8689       561\n",
      "         254     0.1875    0.0789    0.1111        38\n",
      "         255     0.4302    0.5362    0.4774        69\n",
      "         264     0.6331    0.6144    0.6236       542\n",
      "         269     0.4238    0.5333    0.4723       120\n",
      "         276     0.3196    0.4189    0.3626        74\n",
      "         284     0.3780    0.2403    0.2938       129\n",
      "         287     0.3933    0.6974    0.5030       304\n",
      "         295     0.7083    0.8095    0.7556        84\n",
      "         306     0.4366    0.3298    0.3758        94\n",
      "         310     0.7992    0.8210    0.8100       257\n",
      "         312     0.4286    0.1765    0.2500        51\n",
      "         319     0.4783    0.6000    0.5323        55\n",
      "         326     0.4000    0.2353    0.2963        34\n",
      "         327     0.4286    0.3947    0.4110        38\n",
      "         345     0.2727    0.2308    0.2500        26\n",
      "         347     0.3818    0.7778    0.5122        27\n",
      "         352     0.3417    0.9472    0.5022       549\n",
      "         362     0.5113    0.8129    0.6278       139\n",
      "         399     0.4729    0.7138    0.5689       269\n",
      "         400     0.4158    0.5683    0.4802       139\n",
      "         401     0.3824    0.4643    0.4194        56\n",
      "         415     0.8462    0.7174    0.7765        46\n",
      "         416     0.8067    0.8768    0.8403       357\n",
      "         426     0.5254    0.7045    0.6019        44\n",
      "         427     0.8750    0.5957    0.7089        47\n",
      "         434     0.5565    0.9100    0.6906       211\n",
      "         476     0.5128    0.8547    0.6410       234\n",
      "         502     0.5503    0.8378    0.6643       111\n",
      "         522     0.4340    0.7419    0.5476        93\n",
      "         532     0.4731    0.8800    0.6154        50\n",
      "          59     0.7541    0.8214    0.7863       112\n",
      "         601     0.6261    0.8675    0.7273        83\n",
      "         611     0.8017    0.9394    0.8651        99\n",
      "         617     0.7222    0.6047    0.6582        43\n",
      "         639     0.2083    0.4839    0.2913        31\n",
      "         668     0.2273    0.1000    0.1389        50\n",
      "         732     0.4000    0.2353    0.2963       102\n",
      "          74     0.1441    0.3902    0.2105        82\n",
      "         755     0.2600    0.3514    0.2989        37\n",
      "          77     0.5667    0.4474    0.5000       152\n",
      "         770     0.4096    0.4595    0.4331        74\n",
      "         772     0.6098    0.6410    0.6250        39\n",
      "          78     0.5285    0.8715    0.6580       319\n",
      "         787     0.6860    0.4552    0.5473       960\n",
      "          79     0.9933    0.4671    0.6354      2552\n",
      "         798     0.7211    0.8217    0.7681       129\n",
      "         835     0.5065    0.8667    0.6393        45\n",
      "         843     0.5323    0.8250    0.6471        40\n",
      "         862     0.4984    0.6978    0.5815       225\n",
      "         863     0.3419    0.3252    0.3333       123\n",
      "          89     0.9887    0.7262    0.8373      1081\n",
      "         908     0.6667    0.5000    0.5714        28\n",
      "         918     0.5353    0.9192    0.6766        99\n",
      "          94     0.4070    0.6078    0.4875       306\n",
      "\n",
      "    accuracy                         0.5982     15508\n",
      "   macro avg     0.5311    0.6167    0.5453     15508\n",
      "weighted avg     0.6922    0.5982    0.6003     15508\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "        \n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f}\")\n",
    "            print(\"Saved best model\")\n",
    "            print(self.f1_scores)\n",
    "\n",
    "# Load JSON data with embeddings\n",
    "with open('balanced_SecureBert_final.pickle', 'rb') as f1:\n",
    "    balanced = pickle.load(f1)\n",
    "\n",
    "with open('test_SecureBert.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "train = np.array([item['cve_description_secureBERT'] for item in balanced if item['cwe'] != 'None'])\n",
    "test = np.array([item['cwe'] for item in balanced if item['cwe'] != 'None'])\n",
    "np.random.seed(42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,test,test_size=0.1,random_state=42)\n",
    "\n",
    "X_test = np.array([item['cve_description_secureBERT'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "label_encoder_test = LabelEncoder()\n",
    "y_test_encoded = label_encoder_test.fit_transform(y_test)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=60, batch_size=32, validation_data=(X_val, label_encoder_train.transform(y_val)), verbose=1, callbacks=[f1_callback])\n",
    "\n",
    "best_model = f1_callback.best_model\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'CWE_classes.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485/485 [==============================] - 1s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8761    0.4157    0.5638      1174\n",
      "         120     0.2766    0.8325    0.4152       203\n",
      "         125     0.7542    0.7780    0.7659       572\n",
      "         134     0.3696    0.8947    0.5231        19\n",
      "         189     0.4725    0.8655    0.6113       119\n",
      "         190     0.5184    0.8086    0.6318       209\n",
      "          20     0.4728    0.1897    0.2707       870\n",
      "         200     0.7646    0.4668    0.5797       647\n",
      "         203     0.6744    0.8056    0.7342        36\n",
      "          22     0.8696    0.8681    0.8689       561\n",
      "         254     0.1875    0.0789    0.1111        38\n",
      "         255     0.4302    0.5362    0.4774        69\n",
      "         264     0.6331    0.6144    0.6236       542\n",
      "         269     0.4238    0.5333    0.4723       120\n",
      "         276     0.3196    0.4189    0.3626        74\n",
      "         284     0.3780    0.2403    0.2938       129\n",
      "         287     0.3933    0.6974    0.5030       304\n",
      "         295     0.7083    0.8095    0.7556        84\n",
      "         306     0.4366    0.3298    0.3758        94\n",
      "         310     0.7992    0.8210    0.8100       257\n",
      "         312     0.4286    0.1765    0.2500        51\n",
      "         319     0.4783    0.6000    0.5323        55\n",
      "         326     0.4000    0.2353    0.2963        34\n",
      "         327     0.4286    0.3947    0.4110        38\n",
      "         345     0.2727    0.2308    0.2500        26\n",
      "         347     0.3818    0.7778    0.5122        27\n",
      "         352     0.3417    0.9472    0.5022       549\n",
      "         362     0.5113    0.8129    0.6278       139\n",
      "         399     0.4729    0.7138    0.5689       269\n",
      "         400     0.4158    0.5683    0.4802       139\n",
      "         401     0.3824    0.4643    0.4194        56\n",
      "         415     0.8462    0.7174    0.7765        46\n",
      "         416     0.8067    0.8768    0.8403       357\n",
      "         426     0.5254    0.7045    0.6019        44\n",
      "         427     0.8750    0.5957    0.7089        47\n",
      "         434     0.5565    0.9100    0.6906       211\n",
      "         476     0.5128    0.8547    0.6410       234\n",
      "         502     0.5503    0.8378    0.6643       111\n",
      "         522     0.4340    0.7419    0.5476        93\n",
      "         532     0.4731    0.8800    0.6154        50\n",
      "          59     0.7541    0.8214    0.7863       112\n",
      "         601     0.6261    0.8675    0.7273        83\n",
      "         611     0.8017    0.9394    0.8651        99\n",
      "         617     0.7222    0.6047    0.6582        43\n",
      "         639     0.2083    0.4839    0.2913        31\n",
      "         668     0.2273    0.1000    0.1389        50\n",
      "         732     0.4000    0.2353    0.2963       102\n",
      "          74     0.1441    0.3902    0.2105        82\n",
      "         755     0.2600    0.3514    0.2989        37\n",
      "          77     0.5667    0.4474    0.5000       152\n",
      "         770     0.4096    0.4595    0.4331        74\n",
      "         772     0.6098    0.6410    0.6250        39\n",
      "          78     0.5285    0.8715    0.6580       319\n",
      "         787     0.6860    0.4552    0.5473       960\n",
      "          79     0.9933    0.4671    0.6354      2552\n",
      "         798     0.7211    0.8217    0.7681       129\n",
      "         835     0.5065    0.8667    0.6393        45\n",
      "         843     0.5323    0.8250    0.6471        40\n",
      "         862     0.4984    0.6978    0.5815       225\n",
      "         863     0.3419    0.3252    0.3333       123\n",
      "          89     0.9887    0.7262    0.8373      1081\n",
      "         908     0.6667    0.5000    0.5714        28\n",
      "         918     0.5353    0.9192    0.6766        99\n",
      "          94     0.4070    0.6078    0.4875       306\n",
      "\n",
      "    accuracy                         0.5982     15508\n",
      "   macro avg     0.5311    0.6167    0.5453     15508\n",
      "weighted avg     0.6922    0.5982    0.6003     15508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Save the best model\n",
    "with open('test_SecureBert.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "X_test = np.array([item['cve_description_secureBERT'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "best_model=joblib.load('CWE_classes.joblib')\n",
    "label_encoder_train=joblib.load('label_encoder_train.joblib')\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
